,Models to Add,Priority (1=hi),Class,Task,Reasoning State,Chat Template
,https://huggingface.co/openai/gpt-oss-20b,1,B,text_gen,On (High),"  reasoning: True
  reasoning_params:
    reasoning_effort: high"
,https://huggingface.co/openai/gpt-oss-20b,1,B,text_gen,On (Low),"  reasoning: True
  reasoning_params:
    reasoning_effort: low"
,https://huggingface.co/openai/gpt-oss-20b,1,B,text_gen,On (Medium),"  reasoning: True
  reasoning_params:
    reasoning_effort: medium"
,https://huggingface.co/google/gemma-3-4b-pt,1,A,text_gen,On,  reasoning: True
,https://huggingface.co/HuggingFaceTB/SmolLM3-3B,1,A,text_gen,On,"reasoning: True
"
,https://huggingface.co/HuggingFaceTB/SmolLM3-3B,1,A,text_gen,Off,"reasoning: False
"
,https://huggingface.co/microsoft/Phi-4-reasoning-plus,1,A,text_gen,Off,N/A (default)
,https://huggingface.co/microsoft/Phi-4-reasoning-plus,1,A,text_gen,On,"reasoning: True
"
,https://huggingface.co/Qwen/Qwen2.5-Coder-14B,1,A,text_gen,Off (N/A),N/A (default)
,https://huggingface.co/mistralai/Mistral-Nemo-Instruct-2407,1,A,text_gen,Off (N/A),N/A (default)
,https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503,1,B,text_gen,Off (N/A),N/A (default)
,https://huggingface.co/Qwen/Qwen3-30B-A3B,1,B,text_gen,On,enable_thinking=True
,https://huggingface.co/openai/gpt-oss-120b,1,C,text_gen,On (High),reasoning_effort: high
,https://huggingface.co/openai/gpt-oss-120b,1,C,text_gen,On (Low),"  reasoning: True
  reasoning_params:
    reasoning_effort: low"
,https://huggingface.co/openai/gpt-oss-120b,1,C,text_gen,On (Medium),"  reasoning: True
  reasoning_params:
    reasoning_effort: medium"
,https://huggingface.co/deepseek-ai/DeepSeek-R1,1,C,text_gen,Off,N/A (default)
,https://huggingface.co/deepseek-ai/DeepSeek-R1,1,C,text_gen,On,Thinking Mode: Prepend input with <think>.
,https://huggingface.co/deepseek-ai/DeepSeek-V3.2-Exp,1,C,text_gen,Off (N/A),
,https://huggingface.co/Qwen/Qwen3-Next-80B-A3B-Thinking,1,C,text_gen,On,"Qwen3-Next-80B-A3B-Thinking supports only thinking mode. To enforce model thinking, the default chat template automatically includes <think>. Therefore, it is normal for the model's output to contain only </think> without an explicit opening <think> tag."
,https://huggingface.co/Qwen/Qwen3-Next-80B-A3B-Instruct,1,C,text_gen,On,"Qwen3-Next-80B-A3B-Instruct supports only instruct (non-thinking) mode and does not generate <think></think> blocks in its output.
"
,https://huggingface.co/zai-org/GLM-4.6,1,C,text_gen,Off (N/A),N/A (default)
,https://huggingface.co/ibm-granite/granite-4.0-micro,1,A,text_gen,Off (N/A),N/A (default)
,https://huggingface.co/ibm-granite/granite-4.0-h-tiny,1,A,text_gen,Off (N/A),N/A (default)
,https://huggingface.co/ibm-granite/granite-4.0-h-small,1,C,text_gen,Off (N/A),N/A (default)
,https://huggingface.co/moonshotai/Kimi-K2-Instruct,1,C,text_gen,Off (N/A),N/A (default)
,https://huggingface.co/swiss-ai/Apertus-8B-Instruct-2509 ,1,A,text_gen,Off (N/A),N/A (default)
,https://huggingface.co/swiss-ai/Apertus-70B-Instruct-2509,1,C,text_gen,Off (N/A),N/A (default)
,https://huggingface.co/Qwen/Qwen3-235B-A22B,2,C,text_gen,On,"reasoning: True
"
,https://huggingface.co/Qwen/Qwen3-235B-A22B,2,C,text_gen,Off,"reasoning: False
"
,https://huggingface.co/zai-org/GLM-4.5,2,C,text_gen,Off (N/A),N/A (default)
,https://huggingface.co/MiniMaxAI/MiniMax-M1-80k,2,C,text_gen,Off (N/A),N/A (default)
,https://huggingface.co/openai/gpt-oss-20b,2,B,text_gen,Off (N/A),N/A (default)
,https://huggingface.co/google/gemma-3-270m,2,A,text_gen,Off (N/A),N/A (default)
,https://huggingface.co/google/gemma-3-1b-pt,2,A,text_gen,Off (N/A),N/A (default)
,https://huggingface.co/tencent/Hunyuan-1.8B-Instruct,2,A,text_gen,On,Slow-Thinking Mode (Default): /think before the prompt.
,https://huggingface.co/tencent/Hunyuan-1.8B-Instruct,2,A,text_gen,Off,enable_thinking=False
,https://huggingface.co/Qwen/Qwen3-30B-A3B,2,B,text_gen,Off,enable_thinking=False
,https://huggingface.co/LGAI-EXAONE/EXAONE-4.0-32B,2,B,text_gen,On,enable_thinking=True
,https://huggingface.co/LGAI-EXAONE/EXAONE-4.0-32B,2,B,text_gen,Off,N/A (default)
,https://huggingface.co/mistralai/Magistral-Small-2507,2,B,text_gen,Off (N/A),N/A (default)
,https://huggingface.co/deepseek-ai/DeepSeek-V3,2,C,text_gen,Off (N/A),N/A (default)
,https://huggingface.co/zai-org/GLM-4.15-Air,2,C,text_gen,Off (N/A),N/A
,https://huggingface.co/Qwen/Qwen3-0.6B,3,A,text_gen,On,enable_thinking=True
,https://huggingface.co/Qwen/Qwen3-0.6B,3,A,text_gen,Off,enable_thinking=False
,https://huggingface.co/nvidia/Llama-3_3-Nemotron-Super-49B-v1_5,3,B,text_gen,Off,Reasoning OFF Mode: /no_think in the system prompt.
,https://huggingface.co/nvidia/Llama-3_3-Nemotron-Super-49B-v1_5,3,B,text_gen,On,reasoning: True
,https://huggingface.co/google/gemma-3-27b-pt,3,B,text_gen,Off (N/A),N/A (default)
,https://huggingface.co/deepseek-ai/DeepSeek-R1-0528,3,C,text_gen,Off,N/A (default)
,https://huggingface.co/deepseek-ai/DeepSeek-R1-0528,3,C,text_gen,On,enable_thinking=True
,https://huggingface.co/Qwen/Qwen-Image,3,,image_gen,,N/A (default)
,https://huggingface.co/black-forest-labs/FLUX.1-dev,3,,image_gen,,N/A (default)
,https://huggingface.co/HiDream-ai/HiDream-I1-Full,3,,image_gen,,N/A (default)
,https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-70B,3,C,text_gen,Off,enable_thinking=False
,https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-70B,3,C,text_gen,On,enable_thinking=True
,https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B,3,C,text_gen,Off,enable_thinking=False
,https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B,3,C,text_gen,On,enable_thinking=True
