defaults:
  - benchmark
  - backend: pytorch
  - launcher: process
  - scenario: energy_star
  - _base_
  - _self_

name: text_generation_gptoss

launcher:
  device_isolation: False
  device_isolation_action: warn

backend:
  device: cuda
  device_ids: 0
  no_weights: False
  task: text-generation
  model: openai/gpt-oss-20b
  torch_dtype: bfloat16
  device_map: auto

scenario:
  dataset_name: EnergyStarAI/text_generation
  text_column_name: text
  num_samples: 50
  truncation: True
  iterations: 1

  # Reasoning/thinking model support (optional)
  # Set to True to enable reasoning mode for thinking models
  reasoning: False
  # reasoning_params:
  #   reasoning_effort: high  # Options: low, medium, high (model-specific)
  #   # Alternative model-specific parameters:
  #   # thinking_budget: 1000  # Token budget for thinking (DeepSeek-R1, etc.)
  #   # cot_depth: 3  # Chain-of-thought depth

  input_shapes:
    batch_size: 1
